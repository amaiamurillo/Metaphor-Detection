{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3awJvevx3Ef"
      },
      "source": [
        "# Metaphor Detector for Spanish\n",
        "Reyes Gago Sosa and Amaia Murillo Lekuona\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The effective automated detection of conceptual metaphors poses a significant challenge in NLP tasks due to their subjectivity and abstract nature. This project explores the possibility of detecting them at token labeling level in a binary manner, where a word acts metaphorically compared to its usual meaning. To achieve this, a multilingual language model has been trained in Spanish using the CoMeta dataset, aiming to enhance results through fine-tuning procedures. To evaluate the final performance of the model, a custom dataset consisting of 50 examples has been created. Our experiments show promising results, highlighting the potential of multilingual models in detecting linguistic metaphors across diverse contexts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5zmGWS9yXtd"
      },
      "source": [
        "First we install the required libraries to carry out the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxL442pDVk72",
        "outputId": "2d973b5b-de93-4ce8-f8b8-a6722e6a77b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZNwOA6gFHRW",
        "outputId": "e826e996-647d-4258-ac7a-4b1107e72f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFqk2WCu8ww_",
        "outputId": "adedcc0e-9bf2-4ed3-d25d-81775836b0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBm_gdC0ytlR"
      },
      "source": [
        "## Pre-processing\n",
        "We aim to fine-tune [lwachowiak/Metaphor-Detection-XLMR](https://huggingface.co/lwachowiak/Metaphor-Detection-XLMR) model, trained on the VU Amsterdam Metaphor Corpus, which is restricted to English. To this end, we have selected the [CoMeta](https://ixa-ehu.github.io/cometa/), a corpus for metaphor detection in Spanish, which is available in the Datasets library provided by Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-xyjTMvTGfd"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "from datasets import load_dataset\n",
        "data = load_dataset(\"HiTZ/cometa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqrJ1zhS4taT"
      },
      "source": [
        "The CoMeta dataset comprises only two partitions: train and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E5tgb9-8-jF"
      },
      "outputs": [],
      "source": [
        "train_dataset = data[\"train\"]\n",
        "test_dataset = data[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHYV_86K94Df",
        "outputId": "c6c0e95a-9503-4700-dc64-c884b4031d90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 3,\n",
              " 'tokens': ['Éste',\n",
              "  'es',\n",
              "  'el',\n",
              "  'enfoque',\n",
              "  'que',\n",
              "  'ha',\n",
              "  'defendido',\n",
              "  'desde',\n",
              "  'un',\n",
              "  'principio',\n",
              "  'mi',\n",
              "  'Gobierno',\n",
              "  'y',\n",
              "  'que',\n",
              "  'hoy',\n",
              "  'es',\n",
              "  'generalmente',\n",
              "  'compartido',\n",
              "  'por',\n",
              "  'los',\n",
              "  'países',\n",
              "  'que',\n",
              "  'componen',\n",
              "  'la',\n",
              "  'misión',\n",
              "  '.'],\n",
              " 'tags': [0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0]}"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "# Show an individual examples within the dataset\n",
        "data[\"train\"][3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEGDV9hW6CJO"
      },
      "source": [
        "We create a function to display random examples for analyzing the dataset structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_McaLTh-LK1"
      },
      "outputs": [],
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
        "    display(HTML(df.to_html()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4-gC9PE6QGs"
      },
      "source": [
        "As we can see in the following table, our dataset has two columns: 'tokens' and 'tags'. The former contains lists of tokens that make up sentences, while the latter includes lists of tags assigned to each token in the corresponding sentence. In short, each token has a specific label associated with it.\n",
        "\n",
        "There are two possible labels:\n",
        "* Label 0 refers to literal usage.\n",
        "* Label 1 corresponds to metaphoric usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "fRny7di5-iq3",
        "outputId": "56085ce2-5512-4da1-fdac-93012294078e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2619</td>\n",
              "      <td>[Las, primeras, bajas, de, los, rebeldes, irlandeses, en, el, alzamiento, fueron, dos, activistas, del, de, el, ICA, en, un, frustrado, intento, de, asedio, del, de, el, Castillo, de, Dublín, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>456</td>\n",
              "      <td>[Los, jueces, ,, lehendakari, ,, determinan, responsabilidades, penales, o, administrativas, de, las, actuaciones, que, enjuician, ,, pero, no, pueden, significar, una, coartada, ,, ni, para, que, el, Gobierno, evite, la, intervención, de, su, Comisión, de, Ética, ,, ni, para, que, deje, de, asumir, responsabilidades, políticas, y, ,, sobre, todo, ,, los, mandatos, de, este, Parlamento, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>102</td>\n",
              "      <td>[La, operación, está, sujeta, a, ciertas, ', condiciones, suspensivas, ', ,, como, la, obtención, de, autorizaciones, administrativas, de, acuerdo, con, el, contrato, de, concesión, y, con, la, ley, de, defensa, de, la, competencia, ,, y, a, otros, requisitos, como, la, confirmación, de, los, vendedores, que, deberá, ser, emitida, antes, del, 10, de, octubre, próximo, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1126</td>\n",
              "      <td>[El, dirigente, de, CCOO, admitió, que, hace, falta, un, socio, tecnológico, que, aumente, las, inversiones, en, investigación, y, desarrollo, y, ayude, a, la, compañía, a, acceder, a, nuevos, mercados, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1003</td>\n",
              "      <td>[En, más, de, una, ocasión, tuvo, acceso, a, los, paddock, del, de, el, Gran, Premio, de, Inglaterra, en, el, Circuito, de, Silverstone, ,, así, como, en, otros, circuitos, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>914</td>\n",
              "      <td>[En, 1695, ,, un, grupo, de, indios, teribes, fueron, enviados, a, la, región, de, Boruca, ,, al, a, el, sureste, de, Costa, Rica, ,, y, fundan, el, pueblo, de, San, Francisco, de, Térraba, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>571</td>\n",
              "      <td>[Usted, ha, hecho, referencia, a, una, parte, de, mi, intervención, y, yo, leo, textualmente, lo, que, dije, y, es, que, ', el, Gobierno, ha, asumido, con, humildad, y, claridad, que, hay, ámbitos, de, la, gestión, de, determinados, patrocinios, que, pueden, ser, mejorados, ', .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>419</td>\n",
              "      <td>[Obuchi, ,, de, 62, años, ,, sufrió, un, derrame, cerebral, en, la, madrugada, del, día, 2, de, abril, y, ,, tras, permanecer, seis, semanas, en, estado, de, coma, ,, falleció, en, el, hospital, Yuntendo, de, Tokio, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2771</td>\n",
              "      <td>[Muchos, de, los, que, estáis, hoy, aquí, conocisteis, a, Miguel, Ángel, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2233</td>\n",
              "      <td>[Hasta, ahora, ,, Rayo, y, Deportivo, se, habían, enfrentado, ocho, veces, en, Primera, División, ,, con, un, saldo, de, tres, victorias, del, conjunto, coruñés, y, cinco, empates, .]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Display random examples\n",
        "show_random_elements(data[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYLIzKAo8GTx"
      },
      "source": [
        "We load the tokenizer from the model we intend to fine-tune. The tokenizer splits the inputs, converting the tokens to their corresponding IDs in the pre-trained vocabulary, and formats them as the model expects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Hi-ICJN-2vd"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lwachowiak/Metaphor-Detection-XLMR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT1hWLXo_Pm9",
        "outputId": "6b117bca-86c3-4626-b6a9-7201900106b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [0, 157607, 56660, 16531, 22, 12234, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "# Tokenize an example to see the output\n",
        "tokenizer(\"Estoy ahogada en problemas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vewDKGIl834x"
      },
      "source": [
        "Next we compare the original tokens with the ones returned by the tokenizer, to observe how the tokenizer processes and represents each word in the original sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tGf30H5_ag9",
        "outputId": "672c4427-da1c-46f3-f957-fefb6957e2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Especialistas', 'de', 'las', 'Fuerzas', 'Armadas', 'egipcias', 'afirman', 'que', 'hasta', 'finales', 'de', '1999', 'han', 'eliminado', 'más', 'de', 'dos', 'millones', 'de', 'minas', '.']\n"
          ]
        }
      ],
      "source": [
        "sample = data[\"train\"][5]\n",
        "print(sample[\"tokens\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRnrPKUi_fz1",
        "outputId": "5a0e02f4-cf99-44e2-a228-55e859f899ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁Especial', 'istas', '▁de', '▁las', '▁Fuerza', 's', '▁Armada', 's', '▁e', 'gip', 'cias', '▁afirma', 'n', '▁que', '▁hasta', '▁finales', '▁de', '▁1999', '▁han', '▁elimina', 'do', '▁más', '▁de', '▁dos', '▁millones', '▁de', '▁mina', 's', '▁', '.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "tokenized_input = tokenizer(sample[\"tokens\"], is_split_into_words=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbHzDr2g9fbs"
      },
      "source": [
        "We observe that the tokenizer includes some necessary inputs required by the model, and words that the model does not recognize are split into subtokens. Consequently, as we can see below, the list of input IDs returned by the tokenizer is longer than the list of labels. Therefore, we need to align them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ucg3AgkAHHU",
        "outputId": "87d80ee4-b358-4046-9d0c-658110ed1115"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "len(sample[f\"tags\"]), len(tokenized_input[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lMgmLEbAan-",
        "outputId": "8c139774-6779-49f9-955f-7bdbd015d462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32 32\n"
          ]
        }
      ],
      "source": [
        "word_ids = tokenized_input.word_ids()\n",
        "aligned_labels = [-100 if i is None else sample[\"tags\"][i] for i in word_ids]\n",
        "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsCc-fFy-Tjl"
      },
      "source": [
        "In order to tokenize and align the labels, we will create a function that consists in creating a new label list that reflects the tokenized input structure. For each original word and its resulting subtokens we assign the same label to each subtoken. This way, we ensure a direct correspondence between the input IDs and their respective labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikwWwFJ7AmG_"
      },
      "outputs": [],
      "source": [
        "# Assign labels to all tokens, not just to the first token of each word, to ensure that each subtoken receives a label\n",
        "label_all_tokens = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoahUpaJ--TX"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "\n",
        "    # Create a new label list to store aligned labels\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None, set the label to -100 so they are automatically ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # Set the label for the first token of each word\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, set the label to either the current label or -100, depending on the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        # Append the aligned labels to the labels list\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    # Add the aligned labels to the tokenized inputs\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrikDMq2A0_l",
        "outputId": "d6ed16a8-a600-4fd4-dd5e-123cc30055ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 242, 3561, 37421, 115675, 41, 110, 95, 26895, 10, 82633, 1129, 3701, 88, 33362, 6, 5, 2], [0, 357, 18608, 37363, 1538, 533, 182798, 885, 22, 21, 58342, 24668, 581, 89868, 13, 28090, 170852, 6, 5, 2], [0, 20, 20, 2369, 2168, 151, 2168, 6, 5, 2], [0, 10833, 67, 198, 88, 162936, 41, 256, 187727, 246, 3287, 51, 37004, 324, 44744, 113, 41, 12119, 198, 164489, 42215, 246, 196, 388, 18387, 41, 148347, 19, 21, 6, 55611, 6, 5, 2], [0, 17151, 28528, 140323, 72742, 1500, 157846, 136469, 10, 51, 7733, 8, 105799, 7, 41, 21, 100562, 22, 21, 2924, 3290, 4000, 52441, 5977, 41, 13744, 1011, 2924, 3290, 809, 145, 5543, 88, 130205, 8, 388, 17013, 158, 141514, 180291, 6, 4, 5171, 139214, 184, 139214, 40, 196, 21, 162702, 8, 46094, 141514, 113, 41, 164419, 21, 119031, 146, 31357, 12763, 105244, 10, 388, 50871, 123066, 90, 41, 17432, 1397, 95280, 7, 1011, 2924, 3290, 4000, 52441, 5977, 6, 5, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]]}"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ],
      "source": [
        "# Apply the function to some examples\n",
        "tokenize_and_align_labels(data['train'][:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vnOikeIIqfD"
      },
      "outputs": [],
      "source": [
        "# Apply the function to all examples in both the training and testing sets\n",
        "tokenized_datasets = data.map(tokenize_and_align_labels, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5tRmmSkB7HX"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "In this section, now that our data is pre-processed, we proceed to download and fine-tune the [lwachowiak/Metaphor-Detection-XLMR](https://huggingface.co/lwachowiak/Metaphor-Detection-XLMR) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhOJ3_ILGC5r",
        "outputId": "321fe7dc-f32f-4400-a69f-f2adf5cd004e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to save the fine-tuned model and training results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WkKF56REqD8"
      },
      "outputs": [],
      "source": [
        "# Specify the model we want to fine-tune\n",
        "model_checkpoint = \"lwachowiak/Metaphor-Detection-XLMR\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN-a447vBBUv"
      },
      "outputs": [],
      "source": [
        "# Load the model for token classification\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To instantiate a `Trainer`, we need to define three main components. First, we have to set the training parameters using `TrainingArguments`."
      ],
      "metadata": {
        "id": "AJhWgR4dFU4p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Feu6OxHCYgo"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Set the training parameters\n",
        "model_new = model_checkpoint.split(\"/\")[-1]\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/Colab Notebooks/trabajo final app1/Results\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second component that needs to be defined is the `data_collator`. This is used for batching processed examples together and applying padding to ensuare they are all the same size. The data collator that we will be using for this task can be found in the Transformers library and it not only pads the input sequences but also the corresponding labels."
      ],
      "metadata": {
        "id": "MFagHE9KGShK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh-JSR-nEFBZ"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "# Initialize a data collator for token classification using the tokenizer\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last component is the metric we will use to evaluate the predictions made by our fine-tuned model. Since we are performing token classification, we will load the 'seqeval' metric for sequence labeling evaluation."
      ],
      "metadata": {
        "id": "xdM1ZAVIHkqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4qs03bsG2MJ",
        "outputId": "d823bb46-09a2-456a-e305-881ca4370051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHk-TVUwGbxn",
        "outputId": "15628031-a990-4356-efe3-ce5e49251677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "#Load the metric\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FdfecEgHdk5"
      },
      "outputs": [],
      "source": [
        "# Define the label list\n",
        "label_list = ['O','B-METAPHOR']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the evaluation stage of token classification, predictions are represented as logits, therefore, to obtain the predicted labels, we need to convert predictions to label selecting the logit with highest probability. Additionaly, during training, some tokens may be ignored, indicated by a label of -100. In the post-processing step, we need to ignore these special labels and only consider valid labels. To this end, we create a function to carry out the post-processing and the utilizes the ``seqeval`` metric for evaluation."
      ],
      "metadata": {
        "id": "SHQC3MUgJ_YD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYS0OXU4IBw7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    # Unpack predictions and labels\n",
        "    predictions, labels = p\n",
        "     # Convert predictions to label indices with highest probability\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens) and map indices back to labels\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    # Compute evaluation metrics using 'seqeval'\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have defined the training parameters, the data collator, and the evaluation metric, we instantiate a `Trainer` object to manage the training process.\n",
        "\n",
        "In this step, we select the datasets. As we have mentioned earlier, the dataset only has two partitions: train and test. There is no validation set. Consequently, we have used the test set for the validation or `eval_dataset`."
      ],
      "metadata": {
        "id": "RZ5YVPIsLV01"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQckYBAyIKhu",
        "outputId": "572ce3b9-1092-4f85-86b8-e738358552b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we develop our own metaphor detector for Spanish fine-tuning the original model by calling the `train` method."
      ],
      "metadata": {
        "id": "-G40CLQsL5EV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Wxb8e27TIb2e",
        "outputId": "e43fa1bd-59cb-4424-cbda-ab69901aa1e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [546/546 04:08, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.050257</td>\n",
              "      <td>0.712215</td>\n",
              "      <td>0.435995</td>\n",
              "      <td>0.540881</td>\n",
              "      <td>0.981571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.051097</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.570342</td>\n",
              "      <td>0.614754</td>\n",
              "      <td>0.982202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.049400</td>\n",
              "      <td>0.056720</td>\n",
              "      <td>0.652602</td>\n",
              "      <td>0.588086</td>\n",
              "      <td>0.618667</td>\n",
              "      <td>0.981950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory /content/drive/My Drive/Colab Notebooks/trabajo final app1/Results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=546, training_loss=0.0476525611493177, metrics={'train_runtime': 248.6075, 'train_samples_per_second': 35.067, 'train_steps_per_second': 2.196, 'total_flos': 444560707420344.0, 'train_loss': 0.0476525611493177, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkEFgS-LzATY"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have used the test set for validation in the previous step, the evaluation results we obtain are the same as those observed during the final epoch, shown in the table above."
      ],
      "metadata": {
        "id": "EgFon-arWNvz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ac4Dt_cAKlv9",
        "outputId": "d5160afb-2574-4bcf-9e33-70ee790ff29b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [46/46 00:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.05672011524438858,\n",
              " 'eval_precision': 0.6526019690576652,\n",
              " 'eval_recall': 0.5880861850443599,\n",
              " 'eval_f1': 0.6186666666666667,\n",
              " 'eval_accuracy': 0.9819495724068289,\n",
              " 'eval_runtime': 6.1581,\n",
              " 'eval_samples_per_second': 118.055,\n",
              " 'eval_steps_per_second': 7.47,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the precision, recall and F1-score for the label 1, 'B-METAPHOR', we can use the same function as before to analyze the results. In this case is not necessary. As we observe, the results are the same; however,"
      ],
      "metadata": {
        "id": "uF9unQAeYReZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MRKb4Px1LF71",
        "outputId": "1bbdea59-be9f-4aa9-ce8d-6c50a4235244"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'METAPHOR': {'precision': 0.6526019690576652, 'recall': 0.5880861850443599, 'f1': 0.6186666666666667, 'number': 789}, 'overall_precision': 0.6526019690576652, 'overall_recall': 0.5880861850443599, 'overall_f1': 0.6186666666666667, 'overall_accuracy': 0.9819495724068289}\n"
          ]
        }
      ],
      "source": [
        "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
        "predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "# Remove ignored index (special tokens)\n",
        "true_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "true_labels = [\n",
        "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "\n",
        "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3Ayp0oHu711",
        "outputId": "5323d5eb-c8cf-4c73-858c-bd366c29bbb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (B-METAPHOR): 0.6526019690576652\n",
            "Recall (B-METAPHOR): 0.5880861850443599\n",
            "F1-score (B-METAPHOR): 0.6186666666666667\n",
            "Precision (O): 0.9895086835818968\n",
            "Recall (O): 0.9920064724919094\n",
            "F1-score (O): 0.9907560037493132\n",
            "Weighted Precision: 0.9811203028264416\n",
            "Weighted Recall: 0.9819495724068289\n",
            "Weighted F1-score: 0.9814916379770197\n",
            "Overall Precision: 0.8210553263197811\n",
            "Overall Recall: 0.7900463287681347\n",
            "Overall F1-score: 0.80471133520799\n",
            "Overall Accuracy: 0.9819495724068289\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define true labels and predicted labels\n",
        "y_true = [label for sublist in true_labels for label in sublist]\n",
        "y_pred = [label for sublist in true_predictions for label in sublist]\n",
        "\n",
        "# Calculate precision, recall, and F1-score for each class\n",
        "precision_b_metaphor = precision_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[0]\n",
        "recall_b_metaphor = recall_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[0]\n",
        "f1_b_metaphor = f1_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[0]\n",
        "\n",
        "precision_o = precision_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[1]\n",
        "recall_o = recall_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[1]\n",
        "f1_o = f1_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[1]\n",
        "\n",
        "# Calculate weighted average of metrics\n",
        "weighted_precision = precision_score(y_true, y_pred, average='weighted', labels=['B-METAPHOR', 'O'])\n",
        "weighted_recall = recall_score(y_true, y_pred, average='weighted', labels=['B-METAPHOR', 'O'])\n",
        "weighted_f1 = f1_score(y_true, y_pred, average='weighted', labels=['B-METAPHOR', 'O'])\n",
        "\n",
        "# Calculate overall precision, recall, and F1-score\n",
        "overall_precision = precision_score(y_true, y_pred, average='macro')\n",
        "overall_recall = recall_score(y_true, y_pred, average='macro')\n",
        "overall_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Metrics for 'B-METAPHOR'\n",
        "print(\"Precision (B-METAPHOR):\", precision_b_metaphor)\n",
        "print(\"Recall (B-METAPHOR):\", recall_b_metaphor)\n",
        "print(\"F1-score (B-METAPHOR):\", f1_b_metaphor)\n",
        "\n",
        "# Metrics for 'O'\n",
        "print(\"Precision (O):\", precision_o)\n",
        "print(\"Recall (O):\", recall_o)\n",
        "print(\"F1-score (O):\", f1_o)\n",
        "\n",
        "# Weighted metrics\n",
        "print(\"Weighted Precision:\", weighted_precision)\n",
        "print(\"Weighted Recall:\", weighted_recall)\n",
        "print(\"Weighted F1-score:\", weighted_f1)\n",
        "\n",
        "# Overall metrics\n",
        "print(\"Overall Precision:\", overall_precision)\n",
        "print(\"Overall Recall:\", overall_recall)\n",
        "print(\"Overall F1-score:\", overall_f1)\n",
        "print(\"Overall Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following step, we create a dataframe with the predicted labels and the true labels so we can compare the results."
      ],
      "metadata": {
        "id": "lBR_iamIgLBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "jn9XO5WZLZIH",
        "outputId": "9ff50b14-8a72-44c2-df91-4f7230ff72b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                     Predicted Labels  \\\n",
              "0   O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "1   O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "2                                       O O O O O O O   \n",
              "3   O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "4                                 O O O O O O O O O O   \n",
              "5           O O O O O O B-METAPHOR B-METAPHOR O O O O   \n",
              "6   O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "7   O B-METAPHOR B-METAPHOR B-METAPHOR O O O O O O...   \n",
              "8                             O O O O O O O O O O O O   \n",
              "9   O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "10  O O O O O O O O O O O O O B-METAPHOR O O O B-M...   \n",
              "11  O O O O O O O O O O O O O O O O O O O O O O O O O   \n",
              "12  O O O B-METAPHOR B-METAPHOR B-METAPHOR O O O O...   \n",
              "13  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "14  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "15  O O O O O O O O O O O O O O O B-METAPHOR B-MET...   \n",
              "16                                  O O O O O O O O O   \n",
              "17                              O O O O O O O O O O O   \n",
              "18  O O O O O O O O O O O O O O O O O O O O O B-ME...   \n",
              "19  O O O O O O O O O O O O O O O O O O O O O O O ...   \n",
              "\n",
              "                                          True Labels  \n",
              "0   O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "1   O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "2                                       O O O O O O O  \n",
              "3   O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "4                                 O O O O O O O O O O  \n",
              "5           O O O O O O B-METAPHOR B-METAPHOR O O O O  \n",
              "6   O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "7   O O O O O O O O O B-METAPHOR O O O O O O O O O...  \n",
              "8                             O O O O O O O O O O O O  \n",
              "9   O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "10  O O O O O O O O O O O O O B-METAPHOR O O O O O...  \n",
              "11  O O O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "12  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "13  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "14  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
              "15      O O O O O O O O O O O O O O O O O O O O O O O  \n",
              "16                                  O O O O O O O O O  \n",
              "17                              O O O O O O O O O O O  \n",
              "18  O O O O O O O O O O O O O O O O O O O O O B-ME...  \n",
              "19  O O O O O O O O O O O O O O O O O O O O O O O ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3607d237-f605-43c0-92ae-5ae6555f5655\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Labels</th>\n",
              "      <th>True Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O O O O O O O</td>\n",
              "      <td>O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O O O O O O O O O O</td>\n",
              "      <td>O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>O O O O O O B-METAPHOR B-METAPHOR O O O O</td>\n",
              "      <td>O O O O O O B-METAPHOR B-METAPHOR O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>O B-METAPHOR B-METAPHOR B-METAPHOR O O O O O O...</td>\n",
              "      <td>O O O O O O O O O B-METAPHOR O O O O O O O O O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>O O O O O O O O O O O O</td>\n",
              "      <td>O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>O O O O O O O O O O O O O B-METAPHOR O O O B-M...</td>\n",
              "      <td>O O O O O O O O O O O O O B-METAPHOR O O O O O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>O O O B-METAPHOR B-METAPHOR B-METAPHOR O O O O...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>O O O O O O O O O O O O O O O B-METAPHOR B-MET...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>O O O O O O O O O</td>\n",
              "      <td>O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>O O O O O O O O O O O</td>\n",
              "      <td>O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O B-ME...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O B-ME...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3607d237-f605-43c0-92ae-5ae6555f5655')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3607d237-f605-43c0-92ae-5ae6555f5655 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3607d237-f605-43c0-92ae-5ae6555f5655');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78c4680b-a616-469c-b6dd-55799c6c4066\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78c4680b-a616-469c-b6dd-55799c6c4066')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78c4680b-a616-469c-b6dd-55799c6c4066 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Predicted Labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-METAPHOR B-METAPHOR B-METAPHOR B-METAPHOR O O B-METAPHOR B-METAPHOR O O O O O O\",\n          \"O O O O O O O O O O O\",\n          \"O O O O O O O O O O O O O O O B-METAPHOR B-METAPHOR O O O O O O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"True Labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-METAPHOR B-METAPHOR O O B-METAPHOR B-METAPHOR O O O O O O\",\n          \"O O O O O O O O O O O\",\n          \"O O O O O O O O O O O O O O O O O O O O O O O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "predicted = [' '.join(pred) for pred in true_predictions]\n",
        "true = [' '.join(label) for label in true_labels]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Predicted Labels': predicted,\n",
        "    'True Labels': true\n",
        "})\n",
        "\n",
        "display(df.head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, we generate a confusion matrix to observe the correct and incorrect predictions of our model. This way, we can analyze the model's performance in classifying each class."
      ],
      "metadata": {
        "id": "FPckHshtgc6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "-1DPqvNPLk99",
        "outputId": "7f5563d5-8593-4da6-dd67-22ab2214e631"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "flat_true_labels = [label for sublist in true_labels for label in sublist]\n",
        "flat_predicted_labels = [pred for sublist in true_predictions for pred in sublist]\n",
        "\n",
        "conf_matrix = confusion_matrix(flat_true_labels, flat_predicted_labels, labels=label_list)\n",
        "log_norm = LogNorm(vmin=1, vmax=np.max(conf_matrix))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='YlGnBu', ax=ax, cbar=False, norm=log_norm)\n",
        "\n",
        "ax.set_xticklabels(label_list, rotation=45)\n",
        "ax.set_yticklabels(label_list, rotation=45)\n",
        "ax.set_xlabel('Predicted Labels')\n",
        "ax.set_ylabel('True Labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix shows on its diagonal the true positives, which represent the model's correct predictions. For the 'O' label, we see a high number of correct predictions (30,653), which is expected as most words in a sentence are typically literal, rather than metaphorical. In contrast, for metaphors ('B-METAPHOR'), the model has correctly identified 464 instances, but it has failed to recognize 325 metaphors.\n",
        "\n",
        "Given this context, the F1-score is the metric we should look at closely here, as the high accuracy might be misleading. The high accuracy rate is influenced by the correct predictions of the 'O' label, since most words are non-metaphorical. However, this metric does not reliably reflect the model's cability in correctly identifying metaphors.\n"
      ],
      "metadata": {
        "id": "QKM7xTgLhH_l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY1Bn8TWQwjn"
      },
      "source": [
        "### Experimentation\n",
        "\n",
        "In this section we will employ our fine-tuned model to detect metaphor using a dataset specifically created for this purpose, which is available at <https://github.com/amaiamurillo/metaphor-detection/blob/main/metaphors.txt> and subsequently conduct a qualitative analysis on its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Emhj-1J4RH4l"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMSXRamdM3Hk",
        "outputId": "3112687e-9748-4b91-9157-a11dedb221cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9999783,\n",
              "  'word': 'La',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.8303203,\n",
              "  'word': 'profunda',\n",
              "  'start': 3,\n",
              "  'end': 11},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99878246,\n",
              "  'word': 'soledad de Miley Cyrus o por qué cada vez más',\n",
              "  'start': 12,\n",
              "  'end': 57},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.80603915,\n",
              "  'word': 'estrella',\n",
              "  'start': 58,\n",
              "  'end': 66},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9669302,\n",
              "  'word': 's del pop se niegan a hacer giras.',\n",
              "  'start': 66,\n",
              "  'end': 100}]"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ],
      "source": [
        "model_checkpoint = \"/content/drive/My Drive/Colab Notebooks/trabajo final app1/Results/checkpoint-500\"\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
        ")\n",
        "token_classifier(\"La profunda soledad de Miley Cyrus o por qué cada vez más estrellas del pop se niegan a hacer giras.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSFQOsY1bXjJ",
        "outputId": "bd36df15-56a0-4dd0-87cc-ff5513ed2adc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9961328,\n",
              "  'word': 'En el contexto de la cultura mexicana, noviembre es un mes',\n",
              "  'start': 0,\n",
              "  'end': 58},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9761898,\n",
              "  'word': 'cargado',\n",
              "  'start': 59,\n",
              "  'end': 66},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9994624,\n",
              "  'word': 'de significado y celebraciones.',\n",
              "  'start': 67,\n",
              "  'end': 98}]"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "token_classifier(\"En el contexto de la cultura mexicana, noviembre es un mes cargado de significado y celebraciones.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l8yAz8rb6_D",
        "outputId": "3a08f6de-28a7-4a9e-fc0a-14f0c410be18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.99987775,\n",
              "  'word': 'La Policía detiene a 16 personas en Valencia tras',\n",
              "  'start': 0,\n",
              "  'end': 49},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.74921566,\n",
              "  'word': 'desarticular',\n",
              "  'start': 50,\n",
              "  'end': 62},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99995315,\n",
              "  'word': 'una',\n",
              "  'start': 63,\n",
              "  'end': 66},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.98294836,\n",
              "  'word': 'red',\n",
              "  'start': 67,\n",
              "  'end': 70},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.999183,\n",
              "  'word': 'criminal dedicada al tráfico de drogas.',\n",
              "  'start': 71,\n",
              "  'end': 110}]"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "token_classifier(\"La Policía detiene a 16 personas en Valencia tras desarticular una red criminal dedicada al tráfico de drogas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRoD0IoCc5hs",
        "outputId": "f7dcdb25-df88-4fdd-9bac-69884d522e71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.99203753,\n",
              "  'word': 'Se le pasa el tiempo volando con su juguete.',\n",
              "  'start': 0,\n",
              "  'end': 44}]"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ],
      "source": [
        "token_classifier(\"Se le pasa el tiempo volando con su juguete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YFeeCuIdZF7",
        "outputId": "fd7309fe-7276-434f-be53-3b932570aa73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9993261,\n",
              "  'word': 'Una ingeniera, un arquitecto, un médico y un economista explican el valor de las humanidades en sus disciplinas y lamentan el',\n",
              "  'start': 0,\n",
              "  'end': 125},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.8677397,\n",
              "  'word': 'aislamiento',\n",
              "  'start': 126,\n",
              "  'end': 137},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99986935,\n",
              "  'word': 'entre las dos',\n",
              "  'start': 138,\n",
              "  'end': 151},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.91214997,\n",
              "  'word': 'ramas',\n",
              "  'start': 152,\n",
              "  'end': 157},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99995035,\n",
              "  'word': 'del saber.',\n",
              "  'start': 158,\n",
              "  'end': 168}]"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ],
      "source": [
        "token_classifier(\"Una ingeniera, un arquitecto, un médico y un economista explican el valor de las humanidades en sus disciplinas y lamentan el aislamiento entre las dos ramas del saber.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkhQTBPCeNIZ",
        "outputId": "f4f9df32-bdcd-4f69-f3e8-99a4b6215df6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9986342,\n",
              "  'word': 'El Vaticano exhibe una colección de grabados del siglo XX ocultos durante años por su',\n",
              "  'start': 0,\n",
              "  'end': 85},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.78300476,\n",
              "  'word': 'frágil',\n",
              "  'start': 86,\n",
              "  'end': 92},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99945605,\n",
              "  'word': 'estado.',\n",
              "  'start': 93,\n",
              "  'end': 100}]"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ],
      "source": [
        "token_classifier(\"El Vaticano exhibe una colección de grabados del siglo XX ocultos durante años por su frágil estado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gyggCl0ehlD",
        "outputId": "0258baa4-37a4-4052-dd44-d0a677a08e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9986231,\n",
              "  'word': 'Los gatos también destacan por la necesidad de querer',\n",
              "  'start': 0,\n",
              "  'end': 53},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9640057,\n",
              "  'word': 'saciar',\n",
              "  'start': 54,\n",
              "  'end': 60},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9997597,\n",
              "  'word': 'su curiosidad.',\n",
              "  'start': 61,\n",
              "  'end': 75}]"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "token_classifier(\"Los gatos también destacan por la necesidad de querer saciar su curiosidad.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXzKFUYfexxl",
        "outputId": "1f1f3e68-7ea6-4b3b-ccf5-f6b5c46f0525"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9990559,\n",
              "  'word': 'Una madre de 42 años decide acabar con su vida,',\n",
              "  'start': 0,\n",
              "  'end': 47},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9966601,\n",
              "  'word': 'ahogada',\n",
              "  'start': 48,\n",
              "  'end': 55},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9997977,\n",
              "  'word': 'en problemas personales.',\n",
              "  'start': 56,\n",
              "  'end': 80}]"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ],
      "source": [
        "token_classifier(\"Una madre de 42 años decide acabar con su vida, ahogada en problemas personales.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2p5hH-pfA85",
        "outputId": "4f51a8a3-d0dd-4bb7-c354-2de0dc8c0149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9999576,\n",
              "  'word': 'Nueve de cada diez está',\n",
              "  'start': 0,\n",
              "  'end': 23},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.98894006,\n",
              "  'word': 'abierto',\n",
              "  'start': 24,\n",
              "  'end': 31},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9996335,\n",
              "  'word': 'a nuevas oportunidades laborales.',\n",
              "  'start': 32,\n",
              "  'end': 65}]"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ],
      "source": [
        "token_classifier(\"Nueve de cada diez está abierto a nuevas oportunidades laborales.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fvvYpoBfRXN",
        "outputId": "321aa94b-d878-4699-bfe8-39d2e177d9b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.99938345,\n",
              "  'word': 'En las',\n",
              "  'start': 0,\n",
              "  'end': 6},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.65876746,\n",
              "  'word': 'entrañas',\n",
              "  'start': 7,\n",
              "  'end': 15},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9993682,\n",
              "  'word': 'de la fábrica gallega donde se diseña la primera constelación de satélites 5G española.',\n",
              "  'start': 16,\n",
              "  'end': 103}]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ],
      "source": [
        "token_classifier(\"En las entrañas de la fábrica gallega donde se diseña la primera constelación de satélites 5G española.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zabsaAbCf3uX",
        "outputId": "bfed8869-f663-440c-bfc6-5202d47dec21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9999501,\n",
              "  'word': '¿Cómo se',\n",
              "  'start': 0,\n",
              "  'end': 8},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9677142,\n",
              "  'word': 'sale',\n",
              "  'start': 9,\n",
              "  'end': 13},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9951791,\n",
              "  'word': 'de las relaciones tóxicas y del sufrimiento?.',\n",
              "  'start': 14,\n",
              "  'end': 59}]"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ],
      "source": [
        "token_classifier(\"¿Cómo se sale de las relaciones tóxicas y del sufrimiento?.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiqnqGMtgMRM",
        "outputId": "384f9216-9912-48f1-f53e-e9a8e5ff84c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9997564,\n",
              "  'word': 'El Parlamento Europeo ha decidido empezar una',\n",
              "  'start': 0,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9942168,\n",
              "  'word': 'lucha',\n",
              "  'start': 46,\n",
              "  'end': 51},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99898815,\n",
              "  'word': \"contra el '\",\n",
              "  'start': 52,\n",
              "  'end': 63},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.7626455,\n",
              "  'word': 'scroll',\n",
              "  'start': 63,\n",
              "  'end': 69},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9802091,\n",
              "  'word': \"infinito' para que los usuarios dejen de perder el tiempo en redes sociales.\",\n",
              "  'start': 70,\n",
              "  'end': 146}]"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ],
      "source": [
        "token_classifier(\"El Parlamento Europeo ha decidido empezar una lucha contra el 'scroll infinito' para que los usuarios dejen de perder el tiempo en redes sociales.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PilZxmWrgscP",
        "outputId": "3466ce36-0e4e-4c5a-fd5f-d657f158e744"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.99984777,\n",
              "  'word': 'Hasta en ese caso, después de haber',\n",
              "  'start': 0,\n",
              "  'end': 35},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.5171971,\n",
              "  'word': 'conquista',\n",
              "  'start': 36,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.97630435,\n",
              "  'word': 'do la confianza de la tribu, cuesta mucho trabajo a dichos autores anotar las canciones y ceremonias.',\n",
              "  'start': 45,\n",
              "  'end': 146}]"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ],
      "source": [
        "token_classifier(\"Hasta en ese caso, después de haber conquistado la confianza de la tribu, cuesta mucho trabajo a dichos autores anotar las canciones y ceremonias.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En9ed9ZWhGAw",
        "outputId": "7c6a9f97-aeeb-4db8-db33-ccc6629310ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9995135,\n",
              "  'word': 'El PP pide a Page dejar las palabras',\n",
              "  'start': 0,\n",
              "  'end': 36},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9461682,\n",
              "  'word': 'huecas',\n",
              "  'start': 37,\n",
              "  'end': 43},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9999698,\n",
              "  'word': ', es el momento de',\n",
              "  'start': 43,\n",
              "  'end': 61},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9826103,\n",
              "  'word': 'plantar batalla',\n",
              "  'start': 62,\n",
              "  'end': 77},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.99997544,\n",
              "  'word': '.',\n",
              "  'start': 77,\n",
              "  'end': 78}]"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ],
      "source": [
        "token_classifier(\"El PP pide a Page dejar las palabras huecas, es el momento de plantar batalla.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SEYEqimhWJE",
        "outputId": "46007da2-60d5-4b0c-836a-d065113e38ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9914104,\n",
              "  'word': 'Érguete lo cobijó cuando él',\n",
              "  'start': 0,\n",
              "  'end': 27},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9311057,\n",
              "  'word': 'cayó',\n",
              "  'start': 28,\n",
              "  'end': 32},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9513795,\n",
              "  'word': 'en el vicio de la droga y le ayudó a salir.',\n",
              "  'start': 33,\n",
              "  'end': 76}]"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ],
      "source": [
        "token_classifier(\"Érguete lo cobijó cuando él cayó en el vicio de la droga y le ayudó a salir.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVDMa5WCh8GZ",
        "outputId": "8496e661-da37-4b0d-cf13-a770b4631aa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9839645,\n",
              "  'word': 'Érguete lo cobijó cuando él cayó en la droga y le ayudó a salir.',\n",
              "  'start': 0,\n",
              "  'end': 64}]"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ],
      "source": [
        "token_classifier(\"Érguete lo cobijó cuando él cayó en la droga y le ayudó a salir.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1LblaT2iI7i",
        "outputId": "5049dda8-5898-4129-9ca3-362ade619ae4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9932612,\n",
              "  'word': 'Uno de los mayores temores de alguien que está pasando por una etapa difícil es acabar',\n",
              "  'start': 0,\n",
              "  'end': 86},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.9397952,\n",
              "  'word': 'cayendo',\n",
              "  'start': 87,\n",
              "  'end': 94},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.9686736,\n",
              "  'word': 'en depresión.',\n",
              "  'start': 95,\n",
              "  'end': 108}]"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ],
      "source": [
        "token_classifier(\"Uno de los mayores temores de alguien que está pasando por una etapa difícil es acabar cayendo en depresión.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoBwA2D7ifEk",
        "outputId": "8d4d28c2-a0b2-486b-cf5a-3d9a8a2427bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'LABEL_0',\n",
              "  'score': 0.9518739,\n",
              "  'word': 'Érguete lo cobijó cuando él',\n",
              "  'start': 0,\n",
              "  'end': 27},\n",
              " {'entity_group': 'LABEL_1',\n",
              "  'score': 0.99539316,\n",
              "  'word': 'cayó',\n",
              "  'start': 28,\n",
              "  'end': 32},\n",
              " {'entity_group': 'LABEL_0',\n",
              "  'score': 0.98110044,\n",
              "  'word': 'en el vicio de la droga.',\n",
              "  'start': 33,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ],
      "source": [
        "token_classifier(\"Érguete lo cobijó cuando él cayó en el vicio de la droga.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of the experiment\n",
        "After having observed the model's performance across several representative examples from out dataset, we are going to create a dataframe consisting of the sentences, the tokens of these sentences, the corresponding labels for each token, and the predictions made by out model. Finally, we will compare the true labels and the predicted ones in order to assess the model's abilty to identify metaphors in Spanish."
      ],
      "metadata": {
        "id": "AblWBrOOs-NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/My Drive/Colab Notebooks/trabajo final app1/Dataset/metaphors def.txt\"\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "    sentences = []\n",
        "    tokens_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    tokens = []\n",
        "    labels = []\n",
        "    for line in lines:\n",
        "        # Check if the line is not empty\n",
        "        if line.strip() == '':\n",
        "            if tokens:  # Ensures empty sentences are not added\n",
        "                sentences.append(' '.join(tokens))\n",
        "                tokens_list.append(tokens)\n",
        "                labels_list.append(labels)\n",
        "                tokens = []\n",
        "                labels = []\n",
        "        else:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) == 2:  # Checks if the line has two parts\n",
        "                tokens.append(parts[0])\n",
        "                labels.append(parts[1])\n",
        "    # To add the last sentence if the file does not end on an empty line\n",
        "    if tokens:\n",
        "        sentences.append(' '.join(tokens))\n",
        "        tokens_list.append(tokens)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "# Creating the DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'sentences': sentences,\n",
        "    'tokens': tokens_list,\n",
        "    'labels': labels_list\n",
        "})"
      ],
      "metadata": {
        "id": "tX8so5lNtNeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aqTiv5qYIMrw",
        "outputId": "b7897849-42b7-4d40-ef4b-a10741af6f2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            sentences  \\\n",
              "0   Nuestra percepción del tiempo acaba siendo det...   \n",
              "1   Cáritas lucha contra los problemas de salud me...   \n",
              "2         No hay más remedio que levantar ese ánimo .   \n",
              "3   La del cambio climático es la desconexión de l...   \n",
              "4   En el contexto de la cultura mexicana , noviem...   \n",
              "5   El financiero catalán tiene una idea brillante...   \n",
              "6   El Senado tumba los objetivos de déficit y lle...   \n",
              "7   La Policía detiene a 16 personas en Valencia t...   \n",
              "8       Se le pasa el tiempo volando con su juguete .   \n",
              "9   Un nuevo estudio demuestra que el humor negro ...   \n",
              "10  No existe un argumento sólido que pueda justif...   \n",
              "11  Un conductor drogado y sin carnet siembra el c...   \n",
              "12  Una ingeniera , un arquitecto , un médico y un...   \n",
              "13  El Vaticano exhibe una colección de grabados d...   \n",
              "14  Los gatos también destacan por la necesidad de...   \n",
              "15  Un libro para desmontar mitos acerca de la men...   \n",
              "16  Una madre de 42 años decide acabar con su vida...   \n",
              "17  ¿ Te sientes atascado en tu trabajo ? Esto rec...   \n",
              "18  Nueve de cada diez está abierto a nuevas oport...   \n",
              "19  El Gobierno anuncia un plan de impulso territo...   \n",
              "20  En las entrañas de la fábrica gallega donde se...   \n",
              "21  La inversión extranjera en España se desploma ...   \n",
              "22  La profunda soledad de Miley Cyrus o por qué c...   \n",
              "23  Esta idea terminal florecía gracias a aquellos...   \n",
              "24  ¿ Cómo se sale de las relaciones tóxicas y del...   \n",
              "25  Uno de los mayores temores de alguien que está...   \n",
              "26  Cómo construir una teoría de la conspiración e...   \n",
              "27  El Parlamento Europeo ha decidido empezar una ...   \n",
              "28  Conviene tener en cuenta una serie de factores...   \n",
              "29  Hasta en ese caso , después de haber conquista...   \n",
              "30  El PP pide a Page ' dejar las palabras huecas ...   \n",
              "31  La reputación de Justo Fuentes había llegado a...   \n",
              "32  Se pronunciaban durante las exequias de los re...   \n",
              "33  Érguete lo cobijó cuando él cayó en el vicio d...   \n",
              "34  Si el tiempo es más valioso que el dinero , ¿ ...   \n",
              "35  El coronel Carrasco escuchaba petrificado por ...   \n",
              "36  y el héroe nuestro , decimos , ciego de dolor ...   \n",
              "37  Siento que todo fue un ciego furor : mi vida y...   \n",
              "38  Una especie de rebelión del dolor cicatrizaba ...   \n",
              "39  La policía se presentó en el hotel donde se ho...   \n",
              "40  Los grandes cortes no le van nada bien por cua...   \n",
              "41  Mujeres de todas las edades se pasaban las hor...   \n",
              "42  Manuel Cordero Martín , niño que salvó a una m...   \n",
              "43  A un ciego de nacimiento se le puede explicar ...   \n",
              "44  Una ciudad mítica que se cree existe en la cim...   \n",
              "45  Arbolillo de hojas trifoliadas que florece en ...   \n",
              "46  de casa y , sin saber por qué , variaba el rum...   \n",
              "47  El sol calienta hasta quemar la piel , pero en...   \n",
              "48  Si rompen un objeto no es porque les desagrade...   \n",
              "49  El incendio no destruyó la casa completamente ...   \n",
              "\n",
              "                                               tokens  \\\n",
              "0   [Nuestra, percepción, del, tiempo, acaba, sien...   \n",
              "1   [Cáritas, lucha, contra, los, problemas, de, s...   \n",
              "2   [No, hay, más, remedio, que, levantar, ese, án...   \n",
              "3   [La, del, cambio, climático, es, la, desconexi...   \n",
              "4   [En, el, contexto, de, la, cultura, mexicana, ...   \n",
              "5   [El, financiero, catalán, tiene, una, idea, br...   \n",
              "6   [El, Senado, tumba, los, objetivos, de, défici...   \n",
              "7   [La, Policía, detiene, a, 16, personas, en, Va...   \n",
              "8   [Se, le, pasa, el, tiempo, volando, con, su, j...   \n",
              "9   [Un, nuevo, estudio, demuestra, que, el, humor...   \n",
              "10  [No, existe, un, argumento, sólido, que, pueda...   \n",
              "11  [Un, conductor, drogado, y, sin, carnet, siemb...   \n",
              "12  [Una, ingeniera, ,, un, arquitecto, ,, un, méd...   \n",
              "13  [El, Vaticano, exhibe, una, colección, de, gra...   \n",
              "14  [Los, gatos, también, destacan, por, la, neces...   \n",
              "15  [Un, libro, para, desmontar, mitos, acerca, de...   \n",
              "16  [Una, madre, de, 42, años, decide, acabar, con...   \n",
              "17  [¿, Te, sientes, atascado, en, tu, trabajo, ?,...   \n",
              "18  [Nueve, de, cada, diez, está, abierto, a, nuev...   \n",
              "19  [El, Gobierno, anuncia, un, plan, de, impulso,...   \n",
              "20  [En, las, entrañas, de, la, fábrica, gallega, ...   \n",
              "21  [La, inversión, extranjera, en, España, se, de...   \n",
              "22  [La, profunda, soledad, de, Miley, Cyrus, o, p...   \n",
              "23  [Esta, idea, terminal, florecía, gracias, a, a...   \n",
              "24  [¿, Cómo, se, sale, de, las, relaciones, tóxic...   \n",
              "25  [Uno, de, los, mayores, temores, de, alguien, ...   \n",
              "26  [Cómo, construir, una, teoría, de, la, conspir...   \n",
              "27  [El, Parlamento, Europeo, ha, decidido, empeza...   \n",
              "28  [Conviene, tener, en, cuenta, una, serie, de, ...   \n",
              "29  [Hasta, en, ese, caso, ,, después, de, haber, ...   \n",
              "30  [El, PP, pide, a, Page, ', dejar, las, palabra...   \n",
              "31  [La, reputación, de, Justo, Fuentes, había, ll...   \n",
              "32  [Se, pronunciaban, durante, las, exequias, de,...   \n",
              "33  [Érguete, lo, cobijó, cuando, él, cayó, en, el...   \n",
              "34  [Si, el, tiempo, es, más, valioso, que, el, di...   \n",
              "35  [El, coronel, Carrasco, escuchaba, petrificado...   \n",
              "36  [y, el, héroe, nuestro, ,, decimos, ,, ciego, ...   \n",
              "37  [Siento, que, todo, fue, un, ciego, furor, :, ...   \n",
              "38  [Una, especie, de, rebelión, del, dolor, cicat...   \n",
              "39  [La, policía, se, presentó, en, el, hotel, don...   \n",
              "40  [Los, grandes, cortes, no, le, van, nada, bien...   \n",
              "41  [Mujeres, de, todas, las, edades, se, pasaban,...   \n",
              "42  [Manuel, Cordero, Martín, ,, niño, que, salvó,...   \n",
              "43  [A, un, ciego, de, nacimiento, se, le, puede, ...   \n",
              "44  [Una, ciudad, mítica, que, se, cree, existe, e...   \n",
              "45  [Arbolillo, de, hojas, trifoliadas, que, flore...   \n",
              "46  [de, casa, y, ,, sin, saber, por, qué, ,, vari...   \n",
              "47  [El, sol, calienta, hasta, quemar, la, piel, ,...   \n",
              "48  [Si, rompen, un, objeto, no, es, porque, les, ...   \n",
              "49  [El, incendio, no, destruyó, la, casa, complet...   \n",
              "\n",
              "                                               labels  \n",
              "0   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "1    [O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, O]  \n",
              "2                [O, O, O, O, O, B-METAPHOR, O, O, O]  \n",
              "3   [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "4   [O, O, O, O, O, O, O, O, O, O, O, O, B-METAPHO...  \n",
              "5   [O, O, O, O, O, O, B-METAPHOR, O, O, O, B-META...  \n",
              "6   [O, O, B-METAPHOR, O, O, O, O, O, B-METAPHOR, ...  \n",
              "7   [O, O, B-METAPHOR, O, O, O, O, O, O, B-METAPHO...  \n",
              "8    [O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, O, O]  \n",
              "9   [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...  \n",
              "10         [O, O, O, O, B-METAPHOR, O, O, O, O, O, O]  \n",
              "11  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "12  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-META...  \n",
              "13  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "14   [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O]  \n",
              "15            [O, O, O, B-METAPHOR, O, O, O, O, O, O]  \n",
              "16  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, B-M...  \n",
              "17  [O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O, ...  \n",
              "18         [O, O, O, O, O, B-METAPHOR, O, O, O, O, O]  \n",
              "19   [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O]  \n",
              "20  [O, O, B-METAPHOR, O, O, O, O, O, O, O, O, O, ...  \n",
              "21  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "22  [O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "23  [O, O, O, B-METAPHOR, O, O, O, O, O, B-METAPHO...  \n",
              "24  [O, O, O, B-METAPHOR, O, O, O, B-METAPHOR, O, ...  \n",
              "25  [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...  \n",
              "26  [O, B-METAPHOR, O, O, O, O, O, O, O, B-METAPHO...  \n",
              "27  [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...  \n",
              "28  [O, O, O, O, O, O, O, O, O, O, B-METAPHOR, O, ...  \n",
              "29  [O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O, ...  \n",
              "30  [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...  \n",
              "31  [O, O, O, O, O, O, B-METAPHOR, O, O, B-METAPHO...  \n",
              "32  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "33  [O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...  \n",
              "34  [O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...  \n",
              "35  [O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...  \n",
              "36  [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...  \n",
              "37  [O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...  \n",
              "38  [O, O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, ...  \n",
              "39  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "40  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "41  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "42  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "43  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "44         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
              "45  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "46  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "47  [O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...  \n",
              "48   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
              "49         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c56afae-4dd2-44ac-965b-bb11060b82a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>tokens</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nuestra percepción del tiempo acaba siendo det...</td>\n",
              "      <td>[Nuestra, percepción, del, tiempo, acaba, sien...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cáritas lucha contra los problemas de salud me...</td>\n",
              "      <td>[Cáritas, lucha, contra, los, problemas, de, s...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No hay más remedio que levantar ese ánimo .</td>\n",
              "      <td>[No, hay, más, remedio, que, levantar, ese, án...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La del cambio climático es la desconexión de l...</td>\n",
              "      <td>[La, del, cambio, climático, es, la, desconexi...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>En el contexto de la cultura mexicana , noviem...</td>\n",
              "      <td>[En, el, contexto, de, la, cultura, mexicana, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>El financiero catalán tiene una idea brillante...</td>\n",
              "      <td>[El, financiero, catalán, tiene, una, idea, br...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, B-META...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>El Senado tumba los objetivos de déficit y lle...</td>\n",
              "      <td>[El, Senado, tumba, los, objetivos, de, défici...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, B-METAPHOR, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>La Policía detiene a 16 personas en Valencia t...</td>\n",
              "      <td>[La, Policía, detiene, a, 16, personas, en, Va...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Se le pasa el tiempo volando con su juguete .</td>\n",
              "      <td>[Se, le, pasa, el, tiempo, volando, con, su, j...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Un nuevo estudio demuestra que el humor negro ...</td>\n",
              "      <td>[Un, nuevo, estudio, demuestra, que, el, humor...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>No existe un argumento sólido que pueda justif...</td>\n",
              "      <td>[No, existe, un, argumento, sólido, que, pueda...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Un conductor drogado y sin carnet siembra el c...</td>\n",
              "      <td>[Un, conductor, drogado, y, sin, carnet, siemb...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Una ingeniera , un arquitecto , un médico y un...</td>\n",
              "      <td>[Una, ingeniera, ,, un, arquitecto, ,, un, méd...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-META...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>El Vaticano exhibe una colección de grabados d...</td>\n",
              "      <td>[El, Vaticano, exhibe, una, colección, de, gra...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Los gatos también destacan por la necesidad de...</td>\n",
              "      <td>[Los, gatos, también, destacan, por, la, neces...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Un libro para desmontar mitos acerca de la men...</td>\n",
              "      <td>[Un, libro, para, desmontar, mitos, acerca, de...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Una madre de 42 años decide acabar con su vida...</td>\n",
              "      <td>[Una, madre, de, 42, años, decide, acabar, con...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, B-M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>¿ Te sientes atascado en tu trabajo ? Esto rec...</td>\n",
              "      <td>[¿, Te, sientes, atascado, en, tu, trabajo, ?,...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nueve de cada diez está abierto a nuevas oport...</td>\n",
              "      <td>[Nueve, de, cada, diez, está, abierto, a, nuev...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>El Gobierno anuncia un plan de impulso territo...</td>\n",
              "      <td>[El, Gobierno, anuncia, un, plan, de, impulso,...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>En las entrañas de la fábrica gallega donde se...</td>\n",
              "      <td>[En, las, entrañas, de, la, fábrica, gallega, ...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>La inversión extranjera en España se desploma ...</td>\n",
              "      <td>[La, inversión, extranjera, en, España, se, de...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>La profunda soledad de Miley Cyrus o por qué c...</td>\n",
              "      <td>[La, profunda, soledad, de, Miley, Cyrus, o, p...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Esta idea terminal florecía gracias a aquellos...</td>\n",
              "      <td>[Esta, idea, terminal, florecía, gracias, a, a...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>¿ Cómo se sale de las relaciones tóxicas y del...</td>\n",
              "      <td>[¿, Cómo, se, sale, de, las, relaciones, tóxic...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, B-METAPHOR, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Uno de los mayores temores de alguien que está...</td>\n",
              "      <td>[Uno, de, los, mayores, temores, de, alguien, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Cómo construir una teoría de la conspiración e...</td>\n",
              "      <td>[Cómo, construir, una, teoría, de, la, conspir...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>El Parlamento Europeo ha decidido empezar una ...</td>\n",
              "      <td>[El, Parlamento, Europeo, ha, decidido, empeza...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Conviene tener en cuenta una serie de factores...</td>\n",
              "      <td>[Conviene, tener, en, cuenta, una, serie, de, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-METAPHOR, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Hasta en ese caso , después de haber conquista...</td>\n",
              "      <td>[Hasta, en, ese, caso, ,, después, de, haber, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>El PP pide a Page ' dejar las palabras huecas ...</td>\n",
              "      <td>[El, PP, pide, a, Page, ', dejar, las, palabra...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>La reputación de Justo Fuentes había llegado a...</td>\n",
              "      <td>[La, reputación, de, Justo, Fuentes, había, ll...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Se pronunciaban durante las exequias de los re...</td>\n",
              "      <td>[Se, pronunciaban, durante, las, exequias, de,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Érguete lo cobijó cuando él cayó en el vicio d...</td>\n",
              "      <td>[Érguete, lo, cobijó, cuando, él, cayó, en, el...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Si el tiempo es más valioso que el dinero , ¿ ...</td>\n",
              "      <td>[Si, el, tiempo, es, más, valioso, que, el, di...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>El coronel Carrasco escuchaba petrificado por ...</td>\n",
              "      <td>[El, coronel, Carrasco, escuchaba, petrificado...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>y el héroe nuestro , decimos , ciego de dolor ...</td>\n",
              "      <td>[y, el, héroe, nuestro, ,, decimos, ,, ciego, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Siento que todo fue un ciego furor : mi vida y...</td>\n",
              "      <td>[Siento, que, todo, fue, un, ciego, furor, :, ...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Una especie de rebelión del dolor cicatrizaba ...</td>\n",
              "      <td>[Una, especie, de, rebelión, del, dolor, cicat...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>La policía se presentó en el hotel donde se ho...</td>\n",
              "      <td>[La, policía, se, presentó, en, el, hotel, don...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Los grandes cortes no le van nada bien por cua...</td>\n",
              "      <td>[Los, grandes, cortes, no, le, van, nada, bien...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Mujeres de todas las edades se pasaban las hor...</td>\n",
              "      <td>[Mujeres, de, todas, las, edades, se, pasaban,...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Manuel Cordero Martín , niño que salvó a una m...</td>\n",
              "      <td>[Manuel, Cordero, Martín, ,, niño, que, salvó,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>A un ciego de nacimiento se le puede explicar ...</td>\n",
              "      <td>[A, un, ciego, de, nacimiento, se, le, puede, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Una ciudad mítica que se cree existe en la cim...</td>\n",
              "      <td>[Una, ciudad, mítica, que, se, cree, existe, e...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Arbolillo de hojas trifoliadas que florece en ...</td>\n",
              "      <td>[Arbolillo, de, hojas, trifoliadas, que, flore...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>de casa y , sin saber por qué , variaba el rum...</td>\n",
              "      <td>[de, casa, y, ,, sin, saber, por, qué, ,, vari...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>El sol calienta hasta quemar la piel , pero en...</td>\n",
              "      <td>[El, sol, calienta, hasta, quemar, la, piel, ,...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Si rompen un objeto no es porque les desagrade...</td>\n",
              "      <td>[Si, rompen, un, objeto, no, es, porque, les, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>El incendio no destruyó la casa completamente ...</td>\n",
              "      <td>[El, incendio, no, destruyó, la, casa, complet...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c56afae-4dd2-44ac-965b-bb11060b82a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c56afae-4dd2-44ac-965b-bb11060b82a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c56afae-4dd2-44ac-965b-bb11060b82a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97b2f99b-a1c2-429a-9985-ac5b4405b566\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97b2f99b-a1c2-429a-9985-ac5b4405b566')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97b2f99b-a1c2-429a-9985-ac5b4405b566 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"El Vaticano exhibe una colecci\\u00f3n de grabados del siglo XX ocultos durante a\\u00f1os por su fr\\u00e1gil estado .\",\n          \"La polic\\u00eda se present\\u00f3 en el hotel donde se hospedaban y los levant\\u00f3 de la cama para llevarlos a comisar\\u00eda .\",\n          \"El PP pide a Page ' dejar las palabras huecas ' : ' Es el momento de plantar batalla ' .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's output provides detailed information for each identified entity, including the label, confidence score, the words it encompasses, and its position in the text. However, for our analysis and comparison with true labels, we require a simpler format. In order to match the model's output with the format of the true labels for evaluation, we create a function to process the output."
      ],
      "metadata": {
        "id": "54VIpete_lZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_output(sentence, classification_result):\n",
        "    # Mapping from entity_group to labels\n",
        "    label_mapping = {\n",
        "        \"LABEL_0\": \"O\",\n",
        "        \"LABEL_1\": \"B-METAPHOR\",\n",
        "    }\n",
        "\n",
        "    tokens = sentence.split()\n",
        "\n",
        "    # List to store labels for each token\n",
        "    token_labels = []\n",
        "\n",
        "    # Index to track the current position in the token list\n",
        "    current_token_index = 0\n",
        "\n",
        "    for entity in classification_result:\n",
        "        # Get the corresponding label\n",
        "        label = label_mapping[entity['entity_group']]\n",
        "\n",
        "        # Calculate how many tokens this entity spans\n",
        "        entity_tokens = entity['word'].split()\n",
        "        entity_length = len(entity_tokens)\n",
        "\n",
        "        # Ensure the index does not overflow\n",
        "        entity_length = min(entity_length, len(tokens) - current_token_index)\n",
        "\n",
        "        # Assign the label to each token within the entity\n",
        "        for _ in range(entity_length):\n",
        "            token_labels.append(label)\n",
        "            current_token_index += 1\n",
        "\n",
        "    # Ensure all tokens have labels\n",
        "    while current_token_index < len(tokens):\n",
        "        token_labels.append(\"O\")  # Assume any token not covered by an entity is 'O'\n",
        "        current_token_index += 1\n",
        "\n",
        "    return token_labels\n",
        "\n",
        "# Example\n",
        "sentence = \"The deep loneliness of Miley Cyrus or why more and more pop stars refuse to go on tour.\"\n",
        "classification_result = token_classifier(sentence)  # This would be your classifier's output\n",
        "processed_labels = process_output(sentence, classification_result)\n",
        "\n",
        "print(processed_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HTYF2YitdhB",
        "outputId": "cda4cc9f-e1df-470f-af22-9cf5a559041c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-METAPHOR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we apply the function we have just created to each sentence in our dataset. Then we add the predicted labels in the required format as a new column. This allows us to compare them with the true labels."
      ],
      "metadata": {
        "id": "yeNjuL3gA-OL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSnlumOLIOTk"
      },
      "outputs": [],
      "source": [
        "predicted_labels_list = []\n",
        "\n",
        "for sentence in df['sentences']:\n",
        "    # Classify the sentence\n",
        "    classification_result = token_classifier(sentence)\n",
        "    # Process the classification result to obtain token-level labels\n",
        "    processed_labels = process_output(sentence, classification_result)\n",
        "    # Add the processed result to the list of predicted labels\n",
        "    predicted_labels_list.append(processed_labels)\n",
        "\n",
        "# Add the predicted labels as a new column\n",
        "df['predicted_labels'] = predicted_labels_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mvgf_GT1HJBT",
        "outputId": "ceddf127-9776-4013-a533-6dcdc4db92b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentences  \\\n",
              "0   Nuestra percepción del tiempo acaba siendo det...   \n",
              "1   Cáritas lucha contra los problemas de salud me...   \n",
              "2         No hay más remedio que levantar ese ánimo .   \n",
              "3   La del cambio climático es la desconexión de l...   \n",
              "4   En el contexto de la cultura mexicana , noviem...   \n",
              "5   El financiero catalán tiene una idea brillante...   \n",
              "6   El Senado tumba los objetivos de déficit y lle...   \n",
              "7   La Policía detiene a 16 personas en Valencia t...   \n",
              "8       Se le pasa el tiempo volando con su juguete .   \n",
              "9   Un nuevo estudio demuestra que el humor negro ...   \n",
              "10  No existe un argumento sólido que pueda justif...   \n",
              "11  Un conductor drogado y sin carnet siembra el c...   \n",
              "12  Una ingeniera , un arquitecto , un médico y un...   \n",
              "13  El Vaticano exhibe una colección de grabados d...   \n",
              "14  Los gatos también destacan por la necesidad de...   \n",
              "15  Un libro para desmontar mitos acerca de la men...   \n",
              "16  Una madre de 42 años decide acabar con su vida...   \n",
              "17  ¿ Te sientes atascado en tu trabajo ? Esto rec...   \n",
              "18  Nueve de cada diez está abierto a nuevas oport...   \n",
              "19  El Gobierno anuncia un plan de impulso territo...   \n",
              "20  En las entrañas de la fábrica gallega donde se...   \n",
              "21  La inversión extranjera en España se desploma ...   \n",
              "22  La profunda soledad de Miley Cyrus o por qué c...   \n",
              "23  Esta idea terminal florecía gracias a aquellos...   \n",
              "24  ¿ Cómo se sale de las relaciones tóxicas y del...   \n",
              "25  Uno de los mayores temores de alguien que está...   \n",
              "26  Cómo construir una teoría de la conspiración e...   \n",
              "27  El Parlamento Europeo ha decidido empezar una ...   \n",
              "28  Conviene tener en cuenta una serie de factores...   \n",
              "29  Hasta en ese caso , después de haber conquista...   \n",
              "30  El PP pide a Page ' dejar las palabras huecas ...   \n",
              "31  La reputación de Justo Fuentes había llegado a...   \n",
              "32  Se pronunciaban durante las exequias de los re...   \n",
              "33  Érguete lo cobijó cuando él cayó en el vicio d...   \n",
              "34  Si el tiempo es más valioso que el dinero , ¿ ...   \n",
              "35  El coronel Carrasco escuchaba petrificado por ...   \n",
              "36  y el héroe nuestro , decimos , ciego de dolor ...   \n",
              "37  Siento que todo fue un ciego furor : mi vida y...   \n",
              "38  Una especie de rebelión del dolor cicatrizaba ...   \n",
              "39  La policía se presentó en el hotel donde se ho...   \n",
              "40  Los grandes cortes no le van nada bien por cua...   \n",
              "41  Mujeres de todas las edades se pasaban las hor...   \n",
              "42  Manuel Cordero Martín , niño que salvó a una m...   \n",
              "43  A un ciego de nacimiento se le puede explicar ...   \n",
              "44  Una ciudad mítica que se cree existe en la cim...   \n",
              "45  Arbolillo de hojas trifoliadas que florece en ...   \n",
              "46  de casa y , sin saber por qué , variaba el rum...   \n",
              "47  El sol calienta hasta quemar la piel , pero en...   \n",
              "48  Si rompen un objeto no es porque les desagrade...   \n",
              "49  El incendio no destruyó la casa completamente ...   \n",
              "\n",
              "                                               tokens  \\\n",
              "0   [Nuestra, percepción, del, tiempo, acaba, sien...   \n",
              "1   [Cáritas, lucha, contra, los, problemas, de, s...   \n",
              "2   [No, hay, más, remedio, que, levantar, ese, án...   \n",
              "3   [La, del, cambio, climático, es, la, desconexi...   \n",
              "4   [En, el, contexto, de, la, cultura, mexicana, ...   \n",
              "5   [El, financiero, catalán, tiene, una, idea, br...   \n",
              "6   [El, Senado, tumba, los, objetivos, de, défici...   \n",
              "7   [La, Policía, detiene, a, 16, personas, en, Va...   \n",
              "8   [Se, le, pasa, el, tiempo, volando, con, su, j...   \n",
              "9   [Un, nuevo, estudio, demuestra, que, el, humor...   \n",
              "10  [No, existe, un, argumento, sólido, que, pueda...   \n",
              "11  [Un, conductor, drogado, y, sin, carnet, siemb...   \n",
              "12  [Una, ingeniera, ,, un, arquitecto, ,, un, méd...   \n",
              "13  [El, Vaticano, exhibe, una, colección, de, gra...   \n",
              "14  [Los, gatos, también, destacan, por, la, neces...   \n",
              "15  [Un, libro, para, desmontar, mitos, acerca, de...   \n",
              "16  [Una, madre, de, 42, años, decide, acabar, con...   \n",
              "17  [¿, Te, sientes, atascado, en, tu, trabajo, ?,...   \n",
              "18  [Nueve, de, cada, diez, está, abierto, a, nuev...   \n",
              "19  [El, Gobierno, anuncia, un, plan, de, impulso,...   \n",
              "20  [En, las, entrañas, de, la, fábrica, gallega, ...   \n",
              "21  [La, inversión, extranjera, en, España, se, de...   \n",
              "22  [La, profunda, soledad, de, Miley, Cyrus, o, p...   \n",
              "23  [Esta, idea, terminal, florecía, gracias, a, a...   \n",
              "24  [¿, Cómo, se, sale, de, las, relaciones, tóxic...   \n",
              "25  [Uno, de, los, mayores, temores, de, alguien, ...   \n",
              "26  [Cómo, construir, una, teoría, de, la, conspir...   \n",
              "27  [El, Parlamento, Europeo, ha, decidido, empeza...   \n",
              "28  [Conviene, tener, en, cuenta, una, serie, de, ...   \n",
              "29  [Hasta, en, ese, caso, ,, después, de, haber, ...   \n",
              "30  [El, PP, pide, a, Page, ', dejar, las, palabra...   \n",
              "31  [La, reputación, de, Justo, Fuentes, había, ll...   \n",
              "32  [Se, pronunciaban, durante, las, exequias, de,...   \n",
              "33  [Érguete, lo, cobijó, cuando, él, cayó, en, el...   \n",
              "34  [Si, el, tiempo, es, más, valioso, que, el, di...   \n",
              "35  [El, coronel, Carrasco, escuchaba, petrificado...   \n",
              "36  [y, el, héroe, nuestro, ,, decimos, ,, ciego, ...   \n",
              "37  [Siento, que, todo, fue, un, ciego, furor, :, ...   \n",
              "38  [Una, especie, de, rebelión, del, dolor, cicat...   \n",
              "39  [La, policía, se, presentó, en, el, hotel, don...   \n",
              "40  [Los, grandes, cortes, no, le, van, nada, bien...   \n",
              "41  [Mujeres, de, todas, las, edades, se, pasaban,...   \n",
              "42  [Manuel, Cordero, Martín, ,, niño, que, salvó,...   \n",
              "43  [A, un, ciego, de, nacimiento, se, le, puede, ...   \n",
              "44  [Una, ciudad, mítica, que, se, cree, existe, e...   \n",
              "45  [Arbolillo, de, hojas, trifoliadas, que, flore...   \n",
              "46  [de, casa, y, ,, sin, saber, por, qué, ,, vari...   \n",
              "47  [El, sol, calienta, hasta, quemar, la, piel, ,...   \n",
              "48  [Si, rompen, un, objeto, no, es, porque, les, ...   \n",
              "49  [El, incendio, no, destruyó, la, casa, complet...   \n",
              "\n",
              "                                               labels  \\\n",
              "0   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "1    [O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "2                [O, O, O, O, O, B-METAPHOR, O, O, O]   \n",
              "3   [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...   \n",
              "4   [O, O, O, O, O, O, O, O, O, O, O, O, B-METAPHO...   \n",
              "5   [O, O, O, O, O, O, B-METAPHOR, O, O, O, B-META...   \n",
              "6   [O, O, B-METAPHOR, O, O, O, O, O, B-METAPHOR, ...   \n",
              "7   [O, O, B-METAPHOR, O, O, O, O, O, O, B-METAPHO...   \n",
              "8    [O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, O, O]   \n",
              "9   [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...   \n",
              "10         [O, O, O, O, B-METAPHOR, O, O, O, O, O, O]   \n",
              "11  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...   \n",
              "12  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-META...   \n",
              "13  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "14   [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O]   \n",
              "15            [O, O, O, B-METAPHOR, O, O, O, O, O, O]   \n",
              "16  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, B-M...   \n",
              "17  [O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O, ...   \n",
              "18         [O, O, O, O, O, B-METAPHOR, O, O, O, O, O]   \n",
              "19   [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O]   \n",
              "20  [O, O, B-METAPHOR, O, O, O, O, O, O, O, O, O, ...   \n",
              "21  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...   \n",
              "22  [O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "23  [O, O, O, B-METAPHOR, O, O, O, O, O, B-METAPHO...   \n",
              "24  [O, O, O, B-METAPHOR, O, O, O, B-METAPHOR, O, ...   \n",
              "25  [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...   \n",
              "26  [O, B-METAPHOR, O, O, O, O, O, O, O, B-METAPHO...   \n",
              "27  [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...   \n",
              "28  [O, O, O, O, O, O, O, O, O, O, B-METAPHOR, O, ...   \n",
              "29  [O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O, ...   \n",
              "30  [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...   \n",
              "31  [O, O, O, O, O, O, B-METAPHOR, O, O, B-METAPHO...   \n",
              "32  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "33  [O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...   \n",
              "34  [O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...   \n",
              "35  [O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...   \n",
              "36  [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...   \n",
              "37  [O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...   \n",
              "38  [O, O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, ...   \n",
              "39  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "40  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "41  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...   \n",
              "42  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "43  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "44         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "45  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "46  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "47  [O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...   \n",
              "48   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "49         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "\n",
              "                                     predicted_labels  \n",
              "0   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "1    [O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, O]  \n",
              "2                [O, O, O, O, O, B-METAPHOR, O, O, O]  \n",
              "3   [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "4   [O, O, O, O, O, O, O, O, O, O, O, O, B-METAPHO...  \n",
              "5   [O, O, O, O, O, O, B-METAPHOR, O, O, O, B-META...  \n",
              "6   [O, O, B-METAPHOR, O, O, O, O, O, B-METAPHOR, ...  \n",
              "7   [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, B-M...  \n",
              "8                      [O, O, O, O, O, O, O, O, O, O]  \n",
              "9   [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...  \n",
              "10         [O, O, O, O, B-METAPHOR, O, O, O, O, O, O]  \n",
              "11  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "12  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "13  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "14   [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O]  \n",
              "15            [O, O, O, B-METAPHOR, O, O, O, O, O, O]  \n",
              "16  [O, O, O, O, O, O, O, O, O, O, O, B-METAPHOR, ...  \n",
              "17  [O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O, ...  \n",
              "18         [O, O, O, O, O, B-METAPHOR, O, O, O, O, O]  \n",
              "19   [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O]  \n",
              "20  [O, O, B-METAPHOR, O, O, O, O, O, O, O, O, O, ...  \n",
              "21  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "22  [O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "23  [O, O, O, B-METAPHOR, O, O, O, O, O, B-METAPHO...  \n",
              "24      [O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O]  \n",
              "25  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "26  [O, B-METAPHOR, O, O, O, O, O, O, O, B-METAPHO...  \n",
              "27  [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, B-M...  \n",
              "28  [O, O, O, O, O, O, O, O, O, O, B-METAPHOR, O, ...  \n",
              "29  [O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O, ...  \n",
              "30  [O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...  \n",
              "31  [O, O, O, O, O, O, B-METAPHOR, O, O, B-METAPHO...  \n",
              "32  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "33  [O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...  \n",
              "34  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "35  [O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...  \n",
              "36  [O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...  \n",
              "37  [O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...  \n",
              "38  [O, O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, ...  \n",
              "39  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "40  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "41  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "42  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "43  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "44         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
              "45  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "46  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "47  [O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...  \n",
              "48   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
              "49         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db7dc824-d196-4c79-b2fa-5f5aa6c6e829\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>tokens</th>\n",
              "      <th>labels</th>\n",
              "      <th>predicted_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nuestra percepción del tiempo acaba siendo det...</td>\n",
              "      <td>[Nuestra, percepción, del, tiempo, acaba, sien...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cáritas lucha contra los problemas de salud me...</td>\n",
              "      <td>[Cáritas, lucha, contra, los, problemas, de, s...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No hay más remedio que levantar ese ánimo .</td>\n",
              "      <td>[No, hay, más, remedio, que, levantar, ese, án...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La del cambio climático es la desconexión de l...</td>\n",
              "      <td>[La, del, cambio, climático, es, la, desconexi...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>En el contexto de la cultura mexicana , noviem...</td>\n",
              "      <td>[En, el, contexto, de, la, cultura, mexicana, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>El financiero catalán tiene una idea brillante...</td>\n",
              "      <td>[El, financiero, catalán, tiene, una, idea, br...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, B-META...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, B-META...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>El Senado tumba los objetivos de déficit y lle...</td>\n",
              "      <td>[El, Senado, tumba, los, objetivos, de, défici...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, B-METAPHOR, ...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, B-METAPHOR, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>La Policía detiene a 16 personas en Valencia t...</td>\n",
              "      <td>[La, Policía, detiene, a, 16, personas, en, Va...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, B-M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Se le pasa el tiempo volando con su juguete .</td>\n",
              "      <td>[Se, le, pasa, el, tiempo, volando, con, su, j...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Un nuevo estudio demuestra que el humor negro ...</td>\n",
              "      <td>[Un, nuevo, estudio, demuestra, que, el, humor...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>No existe un argumento sólido que pueda justif...</td>\n",
              "      <td>[No, existe, un, argumento, sólido, que, pueda...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Un conductor drogado y sin carnet siembra el c...</td>\n",
              "      <td>[Un, conductor, drogado, y, sin, carnet, siemb...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Una ingeniera , un arquitecto , un médico y un...</td>\n",
              "      <td>[Una, ingeniera, ,, un, arquitecto, ,, un, méd...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-META...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>El Vaticano exhibe una colección de grabados d...</td>\n",
              "      <td>[El, Vaticano, exhibe, una, colección, de, gra...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Los gatos también destacan por la necesidad de...</td>\n",
              "      <td>[Los, gatos, también, destacan, por, la, neces...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Un libro para desmontar mitos acerca de la men...</td>\n",
              "      <td>[Un, libro, para, desmontar, mitos, acerca, de...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Una madre de 42 años decide acabar con su vida...</td>\n",
              "      <td>[Una, madre, de, 42, años, decide, acabar, con...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, B-M...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-METAPHOR, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>¿ Te sientes atascado en tu trabajo ? Esto rec...</td>\n",
              "      <td>[¿, Te, sientes, atascado, en, tu, trabajo, ?,...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nueve de cada diez está abierto a nuevas oport...</td>\n",
              "      <td>[Nueve, de, cada, diez, está, abierto, a, nuev...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>El Gobierno anuncia un plan de impulso territo...</td>\n",
              "      <td>[El, Gobierno, anuncia, un, plan, de, impulso,...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>En las entrañas de la fábrica gallega donde se...</td>\n",
              "      <td>[En, las, entrañas, de, la, fábrica, gallega, ...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, B-METAPHOR, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>La inversión extranjera en España se desploma ...</td>\n",
              "      <td>[La, inversión, extranjera, en, España, se, de...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>La profunda soledad de Miley Cyrus o por qué c...</td>\n",
              "      <td>[La, profunda, soledad, de, Miley, Cyrus, o, p...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Esta idea terminal florecía gracias a aquellos...</td>\n",
              "      <td>[Esta, idea, terminal, florecía, gracias, a, a...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, B-METAPHO...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>¿ Cómo se sale de las relaciones tóxicas y del...</td>\n",
              "      <td>[¿, Cómo, se, sale, de, las, relaciones, tóxic...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, B-METAPHOR, O, ...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Uno de los mayores temores de alguien que está...</td>\n",
              "      <td>[Uno, de, los, mayores, temores, de, alguien, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Cómo construir una teoría de la conspiración e...</td>\n",
              "      <td>[Cómo, construir, una, teoría, de, la, conspir...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "      <td>[O, B-METAPHOR, O, O, O, O, O, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>El Parlamento Europeo ha decidido empezar una ...</td>\n",
              "      <td>[El, Parlamento, Europeo, ha, decidido, empeza...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, B-M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Conviene tener en cuenta una serie de factores...</td>\n",
              "      <td>[Conviene, tener, en, cuenta, una, serie, de, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-METAPHOR, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, B-METAPHOR, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Hasta en ese caso , después de haber conquista...</td>\n",
              "      <td>[Hasta, en, ese, caso, ,, después, de, haber, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-METAPHOR, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>El PP pide a Page ' dejar las palabras huecas ...</td>\n",
              "      <td>[El, PP, pide, a, Page, ', dejar, las, palabra...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-METAPHOR, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>La reputación de Justo Fuentes había llegado a...</td>\n",
              "      <td>[La, reputación, de, Justo, Fuentes, había, ll...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, B-METAPHO...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, B-METAPHO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Se pronunciaban durante las exequias de los re...</td>\n",
              "      <td>[Se, pronunciaban, durante, las, exequias, de,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Érguete lo cobijó cuando él cayó en el vicio d...</td>\n",
              "      <td>[Érguete, lo, cobijó, cuando, él, cayó, en, el...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Si el tiempo es más valioso que el dinero , ¿ ...</td>\n",
              "      <td>[Si, el, tiempo, es, más, valioso, que, el, di...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>El coronel Carrasco escuchaba petrificado por ...</td>\n",
              "      <td>[El, coronel, Carrasco, escuchaba, petrificado...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>y el héroe nuestro , decimos , ciego de dolor ...</td>\n",
              "      <td>[y, el, héroe, nuestro, ,, decimos, ,, ciego, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-METAPHOR, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Siento que todo fue un ciego furor : mi vida y...</td>\n",
              "      <td>[Siento, que, todo, fue, un, ciego, furor, :, ...</td>\n",
              "      <td>[O, O, O, O, O, B-METAPHOR, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Una especie de rebelión del dolor cicatrizaba ...</td>\n",
              "      <td>[Una, especie, de, rebelión, del, dolor, cicat...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, ...</td>\n",
              "      <td>[O, O, O, B-METAPHOR, O, O, B-METAPHOR, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>La policía se presentó en el hotel donde se ho...</td>\n",
              "      <td>[La, policía, se, presentó, en, el, hotel, don...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Los grandes cortes no le van nada bien por cua...</td>\n",
              "      <td>[Los, grandes, cortes, no, le, van, nada, bien...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Mujeres de todas las edades se pasaban las hor...</td>\n",
              "      <td>[Mujeres, de, todas, las, edades, se, pasaban,...</td>\n",
              "      <td>[O, O, O, O, O, O, B-METAPHOR, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Manuel Cordero Martín , niño que salvó a una m...</td>\n",
              "      <td>[Manuel, Cordero, Martín, ,, niño, que, salvó,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>A un ciego de nacimiento se le puede explicar ...</td>\n",
              "      <td>[A, un, ciego, de, nacimiento, se, le, puede, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Una ciudad mítica que se cree existe en la cim...</td>\n",
              "      <td>[Una, ciudad, mítica, que, se, cree, existe, e...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Arbolillo de hojas trifoliadas que florece en ...</td>\n",
              "      <td>[Arbolillo, de, hojas, trifoliadas, que, flore...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>de casa y , sin saber por qué , variaba el rum...</td>\n",
              "      <td>[de, casa, y, ,, sin, saber, por, qué, ,, vari...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>El sol calienta hasta quemar la piel , pero en...</td>\n",
              "      <td>[El, sol, calienta, hasta, quemar, la, piel, ,...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[O, O, O, O, B-METAPHOR, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Si rompen un objeto no es porque les desagrade...</td>\n",
              "      <td>[Si, rompen, un, objeto, no, es, porque, les, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>El incendio no destruyó la casa completamente ...</td>\n",
              "      <td>[El, incendio, no, destruyó, la, casa, complet...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db7dc824-d196-4c79-b2fa-5f5aa6c6e829')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db7dc824-d196-4c79-b2fa-5f5aa6c6e829 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db7dc824-d196-4c79-b2fa-5f5aa6c6e829');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7f4e653-aa4b-445b-88b7-5387256d8e6f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7f4e653-aa4b-445b-88b7-5387256d8e6f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7f4e653-aa4b-445b-88b7-5387256d8e6f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"El Vaticano exhibe una colecci\\u00f3n de grabados del siglo XX ocultos durante a\\u00f1os por su fr\\u00e1gil estado .\",\n          \"La polic\\u00eda se present\\u00f3 en el hotel donde se hospedaban y los levant\\u00f3 de la cama para llevarlos a comisar\\u00eda .\",\n          \"El PP pide a Page ' dejar las palabras huecas ' : ' Es el momento de plantar batalla ' .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 231
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before visualizing the model's predictions with a confusion matrix, we compute the metrics, focusing on precision, recall and F1-score for the 'B-METAPHOR' label."
      ],
      "metadata": {
        "id": "eferXhb2B54P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVLgjfyUtbIc",
        "outputId": "bd3694ba-e3d4-4b49-fbde-5ed6166198f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (B-METAPHOR): 0.8653846153846154\n",
            "Recall (B-METAPHOR): 0.6617647058823529\n",
            "F1-score (B-METAPHOR): 0.75\n",
            "Precision (O): 0.9741863075196409\n",
            "Recall (O): 0.992\n",
            "F1-score (O): 0.9830124575311439\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the real and predicted labels\n",
        "y_true = [label for sublist in df['labels'] for label in sublist]\n",
        "y_pred = [label for sublist in df['predicted_labels'] for label in sublist]\n",
        "\n",
        "# Calculate precision, recall, and F1-score for each class\n",
        "precision_b_metaphor = precision_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[0]\n",
        "recall_b_metaphor = recall_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[0]\n",
        "f1_b_metaphor = f1_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[0]\n",
        "\n",
        "precision_o = precision_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[1]\n",
        "recall_o = recall_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[1]\n",
        "f1_o = f1_score(y_true, y_pred, labels=['B-METAPHOR', 'O'], average=None)[1]\n",
        "\n",
        "# Metrics for 'B-METAPHOR'\n",
        "print(\"Precision (B-METAPHOR):\", precision_b_metaphor)\n",
        "print(\"Recall (B-METAPHOR):\", recall_b_metaphor)\n",
        "print(\"F1-score (B-METAPHOR):\", f1_b_metaphor)\n",
        "\n",
        "# Metrics for 'O'\n",
        "print(\"Precision (O):\", precision_o)\n",
        "print(\"Recall (O):\", recall_o)\n",
        "print(\"F1-score (O):\", f1_o)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will generate a confusion matrix in order to analyze the correct and incorrect predictions of our model."
      ],
      "metadata": {
        "id": "vRp4NBePDna2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "label_list = ['O', 'B-METAPHOR']\n",
        "\n",
        "# Flatten the lists of true and predicted labels\n",
        "flat_true_labels = [label for sublist in df['labels'] for label in sublist]\n",
        "flat_predicted_labels = [label for sublist in df['predicted_labels'] for label in sublist]\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(flat_true_labels, flat_predicted_labels, labels=label_list)\n",
        "\n",
        "# Apply logarithmic normalization\n",
        "log_norm = LogNorm(vmin=1, vmax=np.max(conf_matrix))\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='YlGnBu', ax=ax, cbar=False, norm=log_norm)\n",
        "\n",
        "ax.set_xticklabels(label_list)\n",
        "ax.set_yticklabels(label_list)\n",
        "ax.set_xlabel('Predicted Labels')\n",
        "ax.set_ylabel('True Labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "LM5Od5C7CLai",
        "outputId": "35f1cf6d-3491-4b3b-e043-def1ed4662ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we focus on the 'B-METAPHOR' label, out of a total of 68 instances, the model correctly identified 45 metaphors. However, it missed 23. This indicates that the model captured approximately 66.18% of the metaphors."
      ],
      "metadata": {
        "id": "J3YEfUyTCvdN"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}